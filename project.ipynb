{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 10 Project\n",
        "\n",
        "In this project, you will implement document search within a question and answer database and assess its performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4B2Ff6lisqH"
      },
      "source": [
        "The full project description and a template notebook are available on GitHub: [Project 10 Materials](https://github.com/bu-cds-dx704/dx704-project-10).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEezzKGSdyXB"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQhkdHNFbwLp"
      },
      "source": [
        "## Part 1: Download the SQuAD-explorer Data Set\n",
        "\n",
        "You may use the code provided below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KDN4uTycILU",
        "outputId": "263d0284-de7d-493e-c40f-92161d739ac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'SQuAD-explorer' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rajpurkar/SQuAD-explorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "W7Cgmz-lVmBF"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "kXc87YHZVsOz"
      },
      "outputs": [],
      "source": [
        "with open(\"SQuAD-explorer/dataset/train-v1.1.json\") as fp:\n",
        "    train_data = json.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaYKgEa3V149",
        "outputId": "d512a1ae-7e36-4675-c3b9-05ebea9bf9df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJrdzIqwV3FK",
        "outputId": "78415ac7-f68a-4179-cc19-6ccd18c00b33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['data', 'version']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(train_data.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbru7Z_UV74r",
        "outputId": "5c90d6d6-e0db-459e-fc99-8c59e0d7ee54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data[\"data\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvLq8Xo_V-Ji",
        "outputId": "214682af-3013-4c9c-a344-1953dd6e7120"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "442"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data[\"data\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIaSECnAWBv7",
        "outputId": "d9e182f7-22c8-4f9b-c756-adacde1112ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data[\"data\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze4bVs4bWJ7l",
        "outputId": "9dc04b5a-0943-4cb2-d78b-c137545a35ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['title', 'paragraphs'])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[\"data\"][0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uIwF0bTeWMEC",
        "outputId": "357ae956-3930-418f-e822-62de93d2fcb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'University_of_Notre_Dame'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[\"data\"][0][\"title\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YopAkB-WOTW",
        "outputId": "e2767d66-e39b-40f4-bd42-47a40c9240ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data[\"data\"][0][\"paragraphs\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Bm3BAIqWRCT",
        "outputId": "da233573-f62c-46ee-9384-16fd6a110ed3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
              " 'qas': [{'answers': [{'answer_start': 515,\n",
              "     'text': 'Saint Bernadette Soubirous'}],\n",
              "   'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
              "   'id': '5733be284776f41900661182'},\n",
              "  {'answers': [{'answer_start': 188, 'text': 'a copper statue of Christ'}],\n",
              "   'question': 'What is in front of the Notre Dame Main Building?',\n",
              "   'id': '5733be284776f4190066117f'},\n",
              "  {'answers': [{'answer_start': 279, 'text': 'the Main Building'}],\n",
              "   'question': 'The Basilica of the Sacred heart at Notre Dame is beside to which structure?',\n",
              "   'id': '5733be284776f41900661180'},\n",
              "  {'answers': [{'answer_start': 381,\n",
              "     'text': 'a Marian place of prayer and reflection'}],\n",
              "   'question': 'What is the Grotto at Notre Dame?',\n",
              "   'id': '5733be284776f41900661181'},\n",
              "  {'answers': [{'answer_start': 92,\n",
              "     'text': 'a golden statue of the Virgin Mary'}],\n",
              "   'question': 'What sits on top of the Main Building at Notre Dame?',\n",
              "   'id': '5733be284776f4190066117e'}]}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[\"data\"][0][\"paragraphs\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI7RL5JTWraU",
        "outputId": "2a09c434-6eb4-4bba-9a60-d323136cfbfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18896"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(len(doc[\"paragraphs\"]) for doc in train_data[\"data\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8oSLkMqvMFF"
      },
      "source": [
        "## Part 2: Restructure JSON Data for Processing\n",
        "\n",
        "Parse the file \"SQuAD-explorer/dataset/train-v1.1.json\" above to produce a file \"parsed.tsv\" with columns document_title, paragraph_index, and paragraph_context.\n",
        "The paragraph_index column should be zero-indexed, so zero for the first paragraph of each document.\n",
        "Use pandas `to_csv` method to write the file since there are many quotes and other issues to handle otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "QJHSCtWWaLAG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " parsed.tsv: (18896, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_title</th>\n",
              "      <th>paragraph_index</th>\n",
              "      <th>paragraph_context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>0</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>1</td>\n",
              "      <td>As at most other universities, Notre Dame's st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>2</td>\n",
              "      <td>The university is the major seat of the Congre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>3</td>\n",
              "      <td>The College of Engineering was established in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>4</td>\n",
              "      <td>All of Notre Dame's undergraduate students are...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             document_title  paragraph_index  \\\n",
              "0  University_of_Notre_Dame                0   \n",
              "1  University_of_Notre_Dame                1   \n",
              "2  University_of_Notre_Dame                2   \n",
              "3  University_of_Notre_Dame                3   \n",
              "4  University_of_Notre_Dame                4   \n",
              "\n",
              "                                   paragraph_context  \n",
              "0  Architecturally, the school has a Catholic cha...  \n",
              "1  As at most other universities, Notre Dame's st...  \n",
              "2  The university is the major seat of the Congre...  \n",
              "3  The College of Engineering was established in ...  \n",
              "4  All of Notre Dame's undergraduate students are...  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "SRC = \"SQuAD-explorer/dataset/train-v1.1.json\" \n",
        "\n",
        "with open(SRC, \"r\", encoding=\"utf-8\") as f:\n",
        "    squad = json.load(f)\n",
        "\n",
        "rows = []\n",
        "for doc in squad[\"data\"]:\n",
        "    title = doc.get(\"title\", \"\")\n",
        "    for i, para in enumerate(doc.get(\"paragraphs\", [])):  \n",
        "        ctx = para.get(\"context\", \"\")\n",
        "        rows.append({\n",
        "            \"document_title\": title,\n",
        "            \"paragraph_index\": i,             \n",
        "            \"paragraph_context\": ctx\n",
        "        })\n",
        "\n",
        "parsed_df = pd.DataFrame(rows, columns=[\"document_title\",\"paragraph_index\",\"paragraph_context\"])\n",
        "\n",
        "parsed_df.to_csv(\"parsed.tsv\", sep=\"\\t\", index=False)\n",
        "print(\" parsed.tsv:\", parsed_df.shape)\n",
        "parsed_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_9VpBX7aNLP"
      },
      "source": [
        "Submit \"parsed.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H7Sr3TdcTqr"
      },
      "source": [
        "## Part 3: Prepare Suitable Paragraph Vectors for Document Search\n",
        "\n",
        "Design and implement paragraph vectors based on their text with length 1024.\n",
        "Note that this will be much smaller than the number of distinct words in the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRkun5bA1J6c"
      },
      "source": [
        "Hint: you can base your vectors on any techniques covered in this module so far.\n",
        "Beware that they will be automatically assessed (along with the question vectors of part 4) to make sure they retain useful information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "v978AkFmdnLD"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import re, json, hashlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "parsed = pd.read_csv(\"parsed.tsv\", sep=\"\\t\")\n",
        "\n",
        "_word_re = re.compile(r\"[A-Za-z]{2,}\")   \n",
        "\n",
        "def tokenize(text: str):\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    return [w.lower() for w in _word_re.findall(text)]\n",
        "\n",
        "docfreq = defaultdict(int)\n",
        "N = len(parsed)\n",
        "\n",
        "for ctx in parsed[\"paragraph_context\"]:\n",
        "    toks = set(tokenize(ctx))\n",
        "    for t in toks:\n",
        "        docfreq[t] += 1\n",
        "\n",
        "def idf(term: str) -> float:\n",
        "    return np.log((N + 1) / (docfreq.get(term, 0) + 1)) + 1.0\n",
        "\n",
        "VEC_DIM = 1024\n",
        "def hashed_index(token: str) -> int:\n",
        "    d = hashlib.md5(token.encode(\"utf-8\")).digest() \n",
        "    return int.from_bytes(d[:8], \"little\") % VEC_DIM\n",
        "\n",
        "vec_rows = []\n",
        "for _, row in parsed.iterrows():\n",
        "    title = row[\"document_title\"]\n",
        "    pidx  = int(row[\"paragraph_index\"])\n",
        "    ctx   = row[\"paragraph_context\"]\n",
        "\n",
        "    toks = tokenize(ctx)\n",
        "    if len(toks) == 0:\n",
        "        vec = np.zeros(VEC_DIM, dtype=np.float32)\n",
        "    else:\n",
        "        counts = Counter(toks)\n",
        "        total = sum(counts.values())\n",
        "        vec = np.zeros(VEC_DIM, dtype=np.float32)\n",
        "\n",
        "        for token, c in counts.items():\n",
        "            tf = c / total\n",
        "            w = tf * idf(token)\n",
        "            j = hashed_index(token)\n",
        "            vec[j] += w\n",
        "\n",
        "        norm = np.linalg.norm(vec)\n",
        "        if norm > 0:\n",
        "            vec = vec / norm\n",
        "\n",
        "    vec_rows.append({\n",
        "        \"document_title\": title,\n",
        "        \"paragraph_index\": pidx,\n",
        "        \"paragraph_vector_json\": json.dumps(vec.tolist())\n",
        "    })\n",
        "\n",
        "para_vecs = pd.DataFrame(vec_rows, columns=[\n",
        "    \"document_title\", \"paragraph_index\", \"paragraph_vector_json\"\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbZRTxludpHC"
      },
      "source": [
        "Save your paragraph vectors in a file \"paragraph-vectors.tsv.gz\" with columns document_title, paragraph_index, and paragraph_vector_json where paragraph_vector_json is a JSON encoded list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGE7ooGVckTC"
      },
      "source": [
        "Hint: don't forget the \".gz\" extension indicating gzip compression.\n",
        "The Pandas `.to_csv` method will automatically add the compression if you save data with a filename ending in \".gz\", so you just need to pass it the right filename."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "nNvDMTE1edGm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " paragraph-vectors.tsv.gz: (18896, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_title</th>\n",
              "      <th>paragraph_index</th>\n",
              "      <th>paragraph_vector_json</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>3</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>4</td>\n",
              "      <td>[0.0, 0.0, 0.11971081048250198, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             document_title  paragraph_index  \\\n",
              "0  University_of_Notre_Dame                0   \n",
              "1  University_of_Notre_Dame                1   \n",
              "2  University_of_Notre_Dame                2   \n",
              "3  University_of_Notre_Dame                3   \n",
              "4  University_of_Notre_Dame                4   \n",
              "\n",
              "                               paragraph_vector_json  \n",
              "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
              "4  [0.0, 0.0, 0.11971081048250198, 0.0, 0.0, 0.0,...  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "para_vecs.to_csv(\"paragraph-vectors.tsv.gz\", sep=\"\\t\", index=False)\n",
        "print(\" paragraph-vectors.tsv.gz:\", para_vecs.shape)\n",
        "para_vecs.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71KxgBp-eeqm"
      },
      "source": [
        "Submit \"paragraph-vectors.tsv.gz\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPL_MR_GeSa1"
      },
      "source": [
        "## Part 4: Encode Question Vectors with the Same Design\n",
        "\n",
        "Read the questions in \"questions.tsv\" and encode them in the same way that you encoded the paragraph vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "75F95fJjpZ3d"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import re, json, hashlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "VEC_DIM = 1024\n",
        "_word_re = re.compile(r\"[A-Za-z]{2,}\")\n",
        "\n",
        "def tokenize(text: str):\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    return [w.lower() for w in _word_re.findall(text)]\n",
        "\n",
        "def hashed_index(token: str) -> int:\n",
        "    d = hashlib.md5(token.encode(\"utf-8\")).digest()\n",
        "    return int.from_bytes(d[:8], \"little\") % VEC_DIM\n",
        "\n",
        "parsed = pd.read_csv(\"parsed.tsv\", sep=\"\\t\")\n",
        "docfreq = defaultdict(int)\n",
        "N = len(parsed)\n",
        "for ctx in parsed[\"paragraph_context\"]:\n",
        "    for t in set(tokenize(ctx)):\n",
        "        docfreq[t] += 1\n",
        "\n",
        "def idf(term: str) -> float:\n",
        "    return np.log((N + 1) / (docfreq.get(term, 0) + 1)) + 1.0\n",
        "\n",
        "qdf = pd.read_csv(\"questions.tsv\", sep=\"\\t\")\n",
        "\n",
        "qid_col = \"question_id\" if \"question_id\" in qdf.columns else \"id\"\n",
        "if \"question\" in qdf.columns:\n",
        "    qtext_col = \"question\"\n",
        "elif \"question_text\" in qdf.columns:\n",
        "    qtext_col = \"question_text\"\n",
        "else:\n",
        "    qtext_col = [c for c in qdf.columns if c != qid_col][0]\n",
        "\n",
        "rows = []\n",
        "for _, r in qdf.iterrows():\n",
        "    qid = r[qid_col]\n",
        "    toks = tokenize(r[qtext_col])\n",
        "\n",
        "    if not toks:\n",
        "        vec = np.zeros(VEC_DIM, dtype=np.float32)\n",
        "    else:\n",
        "        counts = Counter(toks)\n",
        "        total = sum(counts.values())\n",
        "        vec = np.zeros(VEC_DIM, dtype=np.float32)\n",
        "        for token, c in counts.items():\n",
        "            tf = c / total\n",
        "            vec[hashed_index(token)] += tf * idf(token)\n",
        "\n",
        "        n = np.linalg.norm(vec)\n",
        "        if n > 0:\n",
        "            vec = vec / n\n",
        "\n",
        "    rows.append({\n",
        "        \"question_id\": int(qid),\n",
        "        \"question_vector_json\": json.dumps(vec.tolist())\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H5j32O5pb03"
      },
      "source": [
        "Save your question vectors in \"question-vectors.tsv\" with columns question_id and question_vector_json."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "oLyvhIcYpr06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " question-vectors.tsv: (100, 2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>question_vector_json</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>[0.2786942422389984, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   question_id                               question_vector_json\n",
              "0            1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "1            4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "2            7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "3           10  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "4           13  [0.2786942422389984, 0.0, 0.0, 0.0, 0.0, 0.0, ..."
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "qvecs = pd.DataFrame(rows, columns=[\"question_id\", \"question_vector_json\"])\n",
        "qvecs.to_csv(\"question-vectors.tsv\", sep=\"\\t\", index=False)\n",
        "print(\" question-vectors.tsv:\", qvecs.shape)\n",
        "qvecs.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWmcWnJUptZN"
      },
      "source": [
        "Submit \"question-vectors.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pRDyTUxcvCx"
      },
      "source": [
        "## Part 5: Match Questions to Paragraphs using Nearest Neighbors\n",
        "\n",
        "Match your question vectors to paragraph vectors and identify the top 5 paragraph vectors for each question using nearest neighbors.\n",
        "Specifically, use the Euclidean distance between the vectors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "dJlB2SsMqf1F"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "TOPK = 5\n",
        "VEC_DIM = 1024\n",
        "BATCH = 32  \n",
        "\n",
        "pdf = pd.read_csv(\"paragraph-vectors.tsv.gz\", sep=\"\\t\", compression=\"infer\")\n",
        "P_meta = pdf[[\"document_title\", \"paragraph_index\"]].to_numpy(object)\n",
        "\n",
        "P = np.vstack([np.array(json.loads(s), dtype=np.float32) for s in pdf[\"paragraph_vector_json\"]])\n",
        "N, D = P.shape\n",
        "assert D == VEC_DIM\n",
        "\n",
        "P_norm2 = np.einsum(\"ij,ij->i\", P, P)\n",
        "\n",
        "qdf = pd.read_csv(\"question-vectors.tsv\", sep=\"\\t\")\n",
        "Q_ids = qdf[\"question_id\"].to_numpy(int)\n",
        "Q = np.vstack([np.array(json.loads(s), dtype=np.float32) for s in qdf[\"question_vector_json\"]])\n",
        "M, D2 = Q.shape\n",
        "assert D2 == VEC_DIM\n",
        "\n",
        "Q_norm2 = np.einsum(\"ij,ij->i\", Q, Q)\n",
        "\n",
        "def topk_smallest(dist_row, k):\n",
        "    idx = np.argpartition(dist_row, k)[:k]\n",
        "    order = np.argsort(dist_row[idx])\n",
        "    return idx[order]\n",
        "\n",
        "rows = []\n",
        "\n",
        "for start in range(0, M, BATCH):\n",
        "    stop = min(start + BATCH, M)\n",
        "    Qb = Q[start:stop]                       \n",
        "\n",
        "    dot = Qb @ P.T                            \n",
        "    dist2 = (Q_norm2[start:stop, None] + P_norm2[None, :] - 2.0 * dot)\n",
        "\n",
        "    np.maximum(dist2, 0.0, out=dist2)\n",
        "\n",
        "    for i in range(dist2.shape[0]):\n",
        "        qid = Q_ids[start + i]\n",
        "        drow = dist2[i]\n",
        "        idxs = topk_smallest(drow, TOPK)\n",
        "        for rank, j in enumerate(idxs, start=1):\n",
        "            rows.append({\n",
        "                \"question_id\": int(qid),\n",
        "                \"question_rank\": rank,\n",
        "                \"document_title\": P_meta[j, 0],\n",
        "                \"paragraph_index\": int(P_meta[j, 1]),\n",
        "            })\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvjW3nP-qkSk"
      },
      "source": [
        "Save your top matches in a file \"question-matches.tsv\" with columns question_id, question_rank, document_title, and paragraph_index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "heaNwWMlrAwv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " question-matches.tsv: (500, 4)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>question_rank</th>\n",
              "      <th>document_title</th>\n",
              "      <th>paragraph_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Sahara</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Houston</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Mandolin</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Association_football</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Liberal_Party_of_Australia</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>BeiDou_Navigation_Satellite_System</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>BeiDou_Navigation_Satellite_System</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>BeiDou_Navigation_Satellite_System</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>BeiDou_Navigation_Satellite_System</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>BeiDou_Navigation_Satellite_System</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   question_id  question_rank                      document_title  \\\n",
              "0            1              1                              Sahara   \n",
              "1            1              2                             Houston   \n",
              "2            1              3                            Mandolin   \n",
              "3            1              4                Association_football   \n",
              "4            1              5          Liberal_Party_of_Australia   \n",
              "5            4              1  BeiDou_Navigation_Satellite_System   \n",
              "6            4              2  BeiDou_Navigation_Satellite_System   \n",
              "7            4              3  BeiDou_Navigation_Satellite_System   \n",
              "8            4              4  BeiDou_Navigation_Satellite_System   \n",
              "9            4              5  BeiDou_Navigation_Satellite_System   \n",
              "\n",
              "   paragraph_index  \n",
              "0                8  \n",
              "1               30  \n",
              "2               15  \n",
              "3               21  \n",
              "4               11  \n",
              "5               18  \n",
              "6               13  \n",
              "7                5  \n",
              "8               14  \n",
              "9                7  "
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "matches = pd.DataFrame(rows, columns=[\"question_id\", \"question_rank\", \"document_title\", \"paragraph_index\"])\n",
        "matches.to_csv(\"question-matches.tsv\", sep=\"\\t\", index=False)\n",
        "print(\" question-matches.tsv:\", matches.shape)\n",
        "matches.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0m-ogJjrCK8"
      },
      "source": [
        "Submit \"question-matches.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NftG5ez0tsyy"
      },
      "source": [
        "## Part 6: Spot Check Question and Paragraph Matches\n",
        "\n",
        "Review the paragraphs matched to the first 5 questions (sorted by question_id ascending).\n",
        "Which paragraph was the worst match for each question?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " worst-paragraphs.tsv: (5, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>document_title</th>\n",
              "      <th>paragraph_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Liberal_Party_of_Australia</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4</td>\n",
              "      <td>BeiDou_Navigation_Satellite_System</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7</td>\n",
              "      <td>The_Times</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>10</td>\n",
              "      <td>Roman_Republic</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>13</td>\n",
              "      <td>American_Idol</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    question_id                      document_title  paragraph_index\n",
              "4             1          Liberal_Party_of_Australia               11\n",
              "9             4  BeiDou_Navigation_Satellite_System                7\n",
              "14            7                           The_Times               16\n",
              "19           10                      Roman_Republic               47\n",
              "24           13                       American_Idol               98"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "matches = pd.read_csv(\"question-matches.tsv\", sep=\"\\t\")\n",
        "\n",
        "first_five_qids = sorted(matches[\"question_id\"].unique())[:5]\n",
        "\n",
        "worst_rows = []\n",
        "for qid in first_five_qids:\n",
        "    worst = matches[(matches[\"question_id\"] == qid) & (matches[\"question_rank\"] == 5)]\n",
        "    if not worst.empty:\n",
        "        worst_rows.append(worst.iloc[0][[\"question_id\", \"document_title\", \"paragraph_index\"]])\n",
        "\n",
        "worst_df = pd.DataFrame(worst_rows)\n",
        "worst_df.to_csv(\"worst-paragraphs.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(\" worst-paragraphs.tsv:\", worst_df.shape)\n",
        "worst_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FqfB5lZ087m"
      },
      "source": [
        "Submit \"worst-paragraphs.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHaFK8Z10xnS"
      },
      "source": [
        "Write a file \"worst-paragraphs.tsv\" with three columns question_id, document_title, paragraph_index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smsTLuFcvR-I"
      },
      "source": [
        "## Part 7: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n",
        "You do not need to provide code for data collection if you did that by manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 8: Acknowledgements\n",
        "\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you did this assignment completely on your own, simply write none below.\n",
        "\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for. If you did not use any other libraries, simply write none below.\n",
        "\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy. If you did not use any generative AI tools, simply write none below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " acknowledgements.txt \n"
          ]
        }
      ],
      "source": [
        "acknowledgements = \"\"\"\n",
        "Acknowledgements:\n",
        "I completed this assignment on my own.\n",
        "\n",
        "Libraries Used:\n",
        "none\n",
        "\n",
        "Generative AI Tools:\n",
        "none\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(\"acknowledgements.txt\", \"w\") as f:\n",
        "    f.write(acknowledgements)\n",
        "\n",
        "print(\" acknowledgements.txt \")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
